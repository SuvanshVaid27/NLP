{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Mini-datathon for Text classification on twitter data\n",
    "\n",
    "## <center>Team name: DATA GLADIATORS\n",
    "    \n",
    "<center> Members: Suvansh Vaid, Saurav Gupta, Mohit Gupta\n",
    "    \n",
    "    \n",
    "    \n",
    "## <center>Competition link: https://www.kaggle.com/c/mdss-basic-stream/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOccylFBb68u",
    "outputId": "f8eebdc8-2b5f-41f3-f3a7-7224f169d78f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from itertools import chain\n",
    "import itertools\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import MWETokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "id": "y2C2J83Nb682"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_basic.csv')\n",
    "test = pd.read_csv('test_basic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "AO_CM5wgb683",
    "outputId": "a5795440-6bd7-4606-c3ac-c80b95ab0294"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silencing blm : priti patel\\xe2\\x80\\x99s anti-...</td>\n",
       "      <td>BLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trillian42_ johnbok5 nadiawhittomemp \"\\'silly ...</td>\n",
       "      <td>BLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt errolwebber: tell me, would this be conside...</td>\n",
       "      <td>BLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple won't let parler have an app but still k...</td>\n",
       "      <td>BLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malika_andrews wojespn can we get jlm trending...</td>\n",
       "      <td>BLM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  silencing blm : priti patel\\xe2\\x80\\x99s anti-...   BLM\n",
       "1  trillian42_ johnbok5 nadiawhittomemp \"\\'silly ...   BLM\n",
       "2  rt errolwebber: tell me, would this be conside...   BLM\n",
       "3  apple won't let parler have an app but still k...   BLM\n",
       "4  malika_andrews wojespn can we get jlm trending...   BLM"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_f9E-7nb685",
    "outputId": "bfa7bed1-6bac-4b5c-886e-cc151200515f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26400, 2)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "id": "y8U3_N7BhlF7"
   },
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsHtNy4_hoTc",
    "outputId": "a65f6170-67ef-4bc3-f6e0-31bc8c062839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24329, 2)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dYL0dMYb686",
    "outputId": "e699ffdb-f729-4274-c41f-8814d59e68bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Covid    8692\n",
       "BLM      4990\n",
       "Riots    4100\n",
       "Trump    3333\n",
       "Biden    3214\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Idntifying labels\n",
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "id": "JdtzT2eRb687"
   },
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    \n",
    "    df['tweet'] = df['tweet'].astype(str)\n",
    "    \n",
    "    # Dealing with newline characters\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x.split('\\n')))\n",
    "    \n",
    "    # Cleaning the urls\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'https?://\\S+|www\\.\\S+', '', x)) \n",
    "\n",
    "    # Cleaning the html elements\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'<.*?>', '', x)) \n",
    "    \n",
    "    # tokenize tweets\n",
    "    tokenizer = RegexpTokenizer(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\") #rule based tokenisation               \n",
    "    df['tokens'] = df['tweet'].apply(lambda x : tokenizer.tokenize(x.strip().lower()))\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [y for y in x if y not in stop_words])\n",
    "    \n",
    "    # stemming\n",
    "    stemmer = PorterStemmer() #here porter stemmer is used because it has a lower error rate and is more efficient\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "    \n",
    "    # lemmatizing\n",
    "    #lemmatizer = WordNetLemmatizer() \n",
    "    #df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    \n",
    "    # Removing tokens of length less than 3\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "    \n",
    "    # Converting list of tokens to sentences\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "id": "u9_GrQ92b687"
   },
   "outputs": [],
   "source": [
    "# Pre processing the training data\n",
    "train_processed = pre_process(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "QmO9eY09b688",
    "outputId": "ac993e38-7286-4291-d4a3-6207db620445"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silencing blm : priti patel\\xe2\\x80\\x99s anti-...</td>\n",
       "      <td>BLM</td>\n",
       "      <td>silenc blm priti patel xe2 x80 x99 anti-protes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trillian42_ johnbok5 nadiawhittomemp \"\\'silly ...</td>\n",
       "      <td>BLM</td>\n",
       "      <td>trillian 42_ johnbok nadiawhittomemp silli lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt errolwebber: tell me, would this be conside...</td>\n",
       "      <td>BLM</td>\n",
       "      <td>errolwebb tell would consid racist xe2 x80 x9d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple won't let parler have an app but still k...</td>\n",
       "      <td>BLM</td>\n",
       "      <td>appl let parler app still keep twitter allow m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malika_andrews wojespn can we get jlm trending...</td>\n",
       "      <td>BLM</td>\n",
       "      <td>malika_andrew wojespn get jlm trend mayb nba p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label  \\\n",
       "0  silencing blm : priti patel\\xe2\\x80\\x99s anti-...   BLM   \n",
       "1  trillian42_ johnbok5 nadiawhittomemp \"\\'silly ...   BLM   \n",
       "2  rt errolwebber: tell me, would this be conside...   BLM   \n",
       "3  apple won't let parler have an app but still k...   BLM   \n",
       "4  malika_andrews wojespn can we get jlm trending...   BLM   \n",
       "\n",
       "                                              tokens  \n",
       "0  silenc blm priti patel xe2 x80 x99 anti-protes...  \n",
       "1  trillian 42_ johnbok nadiawhittomemp silli lit...  \n",
       "2  errolwebb tell would consid racist xe2 x80 x9d...  \n",
       "3  appl let parler app still keep twitter allow m...  \n",
       "4  malika_andrew wojespn get jlm trend mayb nba p...  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "id": "CjUAhawkb68_"
   },
   "outputs": [],
   "source": [
    "# creating count vectorizer\n",
    "#vectorizer = CountVectorizer()\n",
    "#text_tf = vectorizer.fit_transform(train_processed.tokens).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "id": "rOdz8e3jgqPe"
   },
   "outputs": [],
   "source": [
    "# creating tfidf vectorizer\n",
    "tf = TfidfVectorizer(use_idf = True)\n",
    "text_tf = tf.fit_transform(train_processed.tokens).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5wLbNq8jMkr",
    "outputId": "439f76e5-f6b6-4811-f2ac-f5f85b6dc86f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7rSiST7mjya2",
    "outputId": "3a96b38d-df8c-44e6-f2bf-a47e486f4583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid    8692\n",
      "BLM      4990\n",
      "Riots    4100\n",
      "Trump    3333\n",
      "Biden    3214\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = train['label']\n",
    "print (y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing test data\n",
    "test_processed = pre_process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>congratulations rrhdr and publichealthumn!! \\x...</td>\n",
       "      <td>congratul rrhdr publichealthumn xf0 x9f x91 x8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the same people who perpetrated the whitesupre...</td>\n",
       "      <td>peopl perpetr whitesupremaci domesticterrorist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>fannie lou hamer\\n\\nblackhistory\\nblackhistory...</td>\n",
       "      <td>fanni lou hamer nblackhistori nblackhistorymon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kylandyoung williamcson $90 million properly d...</td>\n",
       "      <td>kylandyoung williamcson million properli distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>its the colors for the month for me.\\n.\\nblack...</td>\n",
       "      <td>color month nblacklivesmatt nthat' that post n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_id                                              tweet  \\\n",
       "0         1  congratulations rrhdr and publichealthumn!! \\x...   \n",
       "1         2  the same people who perpetrated the whitesupre...   \n",
       "2         3  fannie lou hamer\\n\\nblackhistory\\nblackhistory...   \n",
       "3         4  kylandyoung williamcson $90 million properly d...   \n",
       "4         5  its the colors for the month for me.\\n.\\nblack...   \n",
       "\n",
       "                                              tokens  \n",
       "0  congratul rrhdr publichealthumn xf0 x9f x91 x8...  \n",
       "1  peopl perpetr whitesupremaci domesticterrorist...  \n",
       "2  fanni lou hamer nblackhistori nblackhistorymon...  \n",
       "3  kylandyoung williamcson million properli distr...  \n",
       "4  color month nblacklivesmatt nthat' that post n...  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tfidf for test data\n",
    "test_tf = tf.transform(test_processed.tokens).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators= 100)\n",
    "rf.fit(text_tf, y)\n",
    "y_pred = rf.predict(test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    'Train_id': test.Train_id,\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "datathon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
